{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "aa92f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Planned datasets - Image (different image sizes/ Different number of classes), \n",
    "##                    Classification (Different feature size / Different number of classes)\n",
    "\n",
    "## Planned models - FC/Dropout, CNN(LeNet)/Resnet/Inception (Maybe include attention)\n",
    "\n",
    "## Predict running time based on Layers/No of params/FLOPs\n",
    "## Calculate total number of computations (based on dataset/model size)\n",
    "## Calculate approx cost on GCP (or any cloud platform)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "09e64282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc(config):\n",
    "    config['hidden_layers'] = len(config['layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    if config['input_dropout'] is not None:\n",
    "        x = tf.keras.layers.Dropout(config['input_dropout'])(input)\n",
    "    else:\n",
    "        x = input\n",
    "    for i in range(config['hidden_layers']):\n",
    "        dim = config['layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "        if config['dropout'] is not None:\n",
    "            x = tf.keras.layers.Dropout(config['dropout'])(x)\n",
    "            \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg_block(x, filters, layers):\n",
    "    for _ in range(layers):\n",
    "        x = tf.keras.layers.Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "def create_vgg(config):\n",
    "    config['num_layers'] = len(config['vgg_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = input\n",
    "    for i in range(config['num_layers']):\n",
    "        block_size = config['vgg_layers'][i]\n",
    "        filter_num = config['filters'][i]\n",
    "        act = 'relu'\n",
    "        x = vgg_block(x,filter_num,block_size)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def inception_block(x, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = tf.keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    # 3x3 conv\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = tf.keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = tf.keras.layers.Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    pool = tf.keras.layers.BatchNormalization()(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = tf.keras.layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    "\n",
    "def create_inception(config):\n",
    "    config['num_layers'] = len(config['inception_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = tf.keras.layers.Conv2D(64, (7,7), padding='valid', activation='relu', strides=(2,2))(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(192, (3,3), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    for i in range(config['num_layers']):\n",
    "        for j in range(config['inception_layers'][i]):\n",
    "            x = inception_block(x,config['f1'][i][j],config['f2_in'][i][j],config['f2_out'][i][j],\n",
    "                                                    config['f3_in'][i][j],config['f3_out'][i][j],config['f4_out'][i][j])\n",
    "        x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def conv_relu(x, filters, kernel_size, strides=1):\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding = 'same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "def identity_block(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def identity_block_small(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block_small(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def resnet_block(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block(x, filters, strides)\n",
    "        for _ in range(reps-1):\n",
    "                x = identity_block(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def resnet_block_small(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block_small(x, filters, strides)\n",
    "        for _ in range(reps):\n",
    "                x = identity_block_small(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def create_resnet(config):\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "\n",
    "    x = conv_relu(input, filters=64, kernel_size=7, strides=2)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 3, strides =2)(x)\n",
    "    if config['small']==False:\n",
    "            x = resnet_block(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    else:\n",
    "            x = resnet_block_small(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block_small(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block_small(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block_small(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(config['output_shape'], activation ='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_base_vgg_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['vgg_layers'] = [params['vgg_layers']] * params['vgg_layers_size']\n",
    "\n",
    "    filters = []\n",
    "    for i in range(params['vgg_layers_size']):\n",
    "        filters.append(params['filters']*(2**i))\n",
    "    config['filters'] = filters\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"VGG\"\n",
    "    return config\n",
    "\n",
    "def create_base_inception_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['inception_layers'] = [params['inception_layers']] * 3\n",
    "\n",
    "    config['f1'] = []\n",
    "    config['f2_in'] = []\n",
    "    config['f2_out'] = []\n",
    "    config['f3_in'] = []\n",
    "    config['f3_out'] = []\n",
    "    config['f4_out'] = []\n",
    "\n",
    "    for val in config['inception_layers']:\n",
    "        config['f1'].append([params['f1']]*val)\n",
    "        config['f2_in'].append([params['f2_in']]*val)\n",
    "        config['f2_out'].append([params['f2_out']]*val)\n",
    "        config['f3_in'].append([params['f3_in']]*val)\n",
    "        config['f3_out'].append([params['f3_out']]*val)\n",
    "        config['f4_out'].append([params['f4_out']]*val)\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"Inception\"\n",
    "    return config\n",
    "\n",
    "def create_base_resnet_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['small'] = False\n",
    "    config['resnet_layers'] = [params['resnet_layers']] * 4\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"ResNet\"\n",
    "    return config\n",
    "\n",
    "def create_base_fc_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = params['input_shape']\n",
    "    config['input_dropout'] = 0.2\n",
    "    config['dropout'] = 0.5\n",
    "\n",
    "    config['layers'] = [1000] * params['hidden_layers']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"FC\"\n",
    "    return config\n",
    "\n",
    "def get_flops(model, batch_size=None,allowed_flops=['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']):\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "\n",
    "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    opts['output'] = 'none'\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
    "                                            run_meta=run_meta, cmd='op', options=opts)\n",
    "    \n",
    "    ret_val = dict()\n",
    "    for fl in allowed_flops:\n",
    "        ret_val[fl] = 0\n",
    "    f = flops.children\n",
    "    while(len(f) > 0):\n",
    "        if f[0].name in allowed_flops:\n",
    "            ret_val[f[0].name] = f[0].total_float_ops\n",
    "        f = f[0].children\n",
    "    return ret_val\n",
    "\n",
    "def get_weights(model):\n",
    "    ret_val = dict()\n",
    "    ret_val['trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.trainable_weights])\n",
    "    ret_val['non_trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.non_trainable_weights])\n",
    "    return ret_val\n",
    "\n",
    "def get_layers(model):\n",
    "    ret_val = dict()\n",
    "    for l in model.layers:\n",
    "        name = l.__class__.__name__\n",
    "        if name in ret_val:\n",
    "            ret_val[name] += 1\n",
    "        else:\n",
    "            ret_val[name] = 1\n",
    "    return ret_val\n",
    "\n",
    "allowed_flops = ['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']\n",
    "def get_model_params(model,batch_size = 64,x_shape=[]):\n",
    "    flops = get_flops(model)\n",
    "    weights = get_weights(model)\n",
    "    layers = get_layers(model)\n",
    "    \n",
    "    return flops,weights,layers\n",
    "\n",
    "model_creator = dict()\n",
    "model_creator['vgg'] = create_vgg\n",
    "model_creator['resnet'] = create_resnet\n",
    "model_creator['inception'] = create_inception\n",
    "model_creator['fc'] = create_fc\n",
    "\n",
    "base_param_creator = dict()\n",
    "base_param_creator['vgg'] = create_base_vgg_config\n",
    "base_param_creator['resnet'] = create_base_resnet_config\n",
    "base_param_creator['inception'] = create_base_inception_config\n",
    "base_param_creator['fc'] = create_base_fc_config\n",
    "\n",
    "def get_single_train_data(output_config):\n",
    "    x = []\n",
    "    y = []\n",
    "    x.append(list(output_config['flops_param'].values()) + \n",
    "             list(output_config['layers_param'].values()) + \n",
    "             list(output_config['weights_param'].values()))\n",
    "    x[-1].append(output_config['input_size'])\n",
    "    x[-1].append(output_config['batch_size'])\n",
    "    x = np.asarray(x).astype('float64')\n",
    "    return x\n",
    "\n",
    "def get_training_time(config,model_name):\n",
    "    input_config = base_param_creator[model_name](config)\n",
    "    model = model_creator[model_name](input_config)\n",
    "    flops,weights,layers = get_model_params(model)\n",
    "    input_config['flops_param'] = flops\n",
    "    input_config['weights_param'] = weights\n",
    "    input_config['layers_param'] = layers\n",
    "    \n",
    "    with open('rf_models.pickle', 'rb') as handle:\n",
    "                models = pickle.load(handle)\n",
    "    \n",
    "    x = get_single_train_data(input_config)\n",
    "    \n",
    "    time = models[model_name].predict(x)[0]\n",
    "    return time * config['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "404be32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 02:20:43.183044: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-12-15 02:20:43.183256: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-12-15 02:20:43.185520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38464 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "2021-12-15 02:20:43.189486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.021ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "275.02431612100906"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_range = dict()\n",
    "vgg_range['input_shape'] = 128\n",
    "vgg_range['input_size'] = 10240\n",
    "vgg_range['vgg_layers'] = 2\n",
    "vgg_range['vgg_layers_size'] = 3 \n",
    "vgg_range['filters'] = 16\n",
    "vgg_range['hidden_layers_size'] = 3\n",
    "vgg_range['hidden_layers'] = 100\n",
    "vgg_range['output_shape'] = 2\n",
    "vgg_range['batch_size'] = 64\n",
    "vgg_range['epochs'] = 100\n",
    "\n",
    "get_training_time(vgg_range,'vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e998a44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c559c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a4230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_range = dict()\n",
    "vgg_range['input_shape'] = [128,1024,15,0]\n",
    "vgg_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "vgg_range['vgg_layers'] = [2,10,9,0]\n",
    "vgg_range['vgg_layers_size'] = [1,7,7,0] \n",
    "vgg_range['filters'] = [4,10,7,1] # Logspace 8\n",
    "vgg_range['hidden_layers_size'] = [1,10,10,0]\n",
    "vgg_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "vgg_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "vgg_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "vgg_params = dict()\n",
    "for key in vgg_range.keys():\n",
    "    val = vgg_range[key]\n",
    "    if val[-1] == 0:\n",
    "        vgg_params[key] = np.linspace(val[0],val[1],num=val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=10).astype('int')\n",
    "\n",
    "inception_range = dict()\n",
    "inception_range['input_shape'] = [128,1024,15,0]\n",
    "inception_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "inception_range['inception_layers'] = [1,5,5,0]\n",
    "inception_range['f1'] = [64,320,5,0]\n",
    "inception_range['f2_in'] = [128,384,5,0]\n",
    "inception_range['f2_out'] = [192,448,5,0]\n",
    "inception_range['f3_in'] = [32,160,5,0]\n",
    "inception_range['f3_out'] = [32,160,5,0]\n",
    "inception_range['f4_out'] = [32,160,5,0]\n",
    "inception_range['hidden_layers_size'] = [1,10,10,0]\n",
    "inception_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "inception_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "inception_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "inception_params = dict()\n",
    "for key in inception_range.keys():\n",
    "    val = inception_range[key]\n",
    "    if val[-1] == 0:\n",
    "        inception_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        inception_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        inception_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "        \n",
    "resnet_range = dict()\n",
    "resnet_range['input_shape'] = [128,1024,15,0]\n",
    "resnet_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "resnet_range['resnet_layers'] = [3,7,5,0]\n",
    "resnet_range['hidden_layers_size'] = [1,10,10,0]\n",
    "resnet_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "resnet_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "resnet_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "resnet_params = dict()\n",
    "for key in resnet_range.keys():\n",
    "    val = resnet_range[key]\n",
    "    if val[-1] == 0:\n",
    "        resnet_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        resnet_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        resnet_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "\n",
    "\n",
    "fc_range = dict()\n",
    "fc_range['input_shape'] = [128,1024,15,0]\n",
    "fc_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "fc_range['hidden_layers'] = [1,10,10,0]\n",
    "fc_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "fc_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "fc_params = dict()\n",
    "for key in fc_range.keys():\n",
    "    val = fc_range[key]\n",
    "    if val[-1] == 0:\n",
    "        fc_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        fc_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        fc_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "        \n",
    "params = dict()\n",
    "params['vgg'] = vgg_params\n",
    "params['resnet'] = resnet_params\n",
    "params['inception'] = inception_params\n",
    "params['fc'] = fc_params\n",
    "\n",
    "def get_time_train_data(folder_name):\n",
    "    x = []\n",
    "    y = []\n",
    "    model_params = params[folder_name]\n",
    "    for key in model_params:\n",
    "    #     if key in ['input_size','batch_size','output_shape']:\n",
    "    #         continue\n",
    "        for value in model_params[key]:\n",
    "            filename = f'{folder_name}/{folder_name}-{key}-{value}.pickle'\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, 'rb') as handle:\n",
    "                    output_config = pickle.load(handle)\n",
    "                    x.append(list(output_config['flops_param'].values()) + \n",
    "                             list(output_config['layers_param'].values()) + \n",
    "                             list(output_config['weights_param'].values()))\n",
    "                    x[-1].append(output_config['input_size'])\n",
    "                    x[-1].append(output_config['batch_size'])\n",
    "                    y.append(list(output_config['train_times']))\n",
    "    x = np.asarray(x).astype('float64')\n",
    "    y = np.asarray(y).astype('float64')\n",
    "    y = np.mean(y,axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_single_time_train_data(output_config):\n",
    "    x = []\n",
    "    y = []\n",
    "    x.append(list(output_config['flops_param'].values()) + \n",
    "             list(output_config['layers_param'].values()) + \n",
    "             list(output_config['weights_param'].values()))\n",
    "    x[-1].append(output_config['input_size'])\n",
    "    x[-1].append(output_config['batch_size'])\n",
    "    y.append(list(output_config['train_times']))\n",
    "    x = np.asarray(x).astype('float64')\n",
    "    y = np.asarray(y).astype('float64')\n",
    "    y = np.mean(y,axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_trained_model(folder_name):\n",
    "    x,y = get_time_train_data(folder_name)\n",
    "    min_error = float('inf')\n",
    "    min_model = None\n",
    "    for i in range(100):\n",
    "        rf = RandomForestRegressor(n_estimators=20)\n",
    "        rf.fit(x, y)\n",
    "        y_pred = rf.predict(x)\n",
    "        error = mean_absolute_percentage_error(y,y_pred)\n",
    "        if error < min_error:\n",
    "            min_loss = error\n",
    "            min_model = rf\n",
    "    y_pred = min_model.predict(x)\n",
    "    print(f'{folder_name} - train MSE : {mean_absolute_percentage_error(y,y_pred)}')\n",
    "    \n",
    "    return min_model\n",
    "\n",
    "models = dict()\n",
    "models['vgg'] = get_trained_model('vgg')\n",
    "models['inception'] = get_trained_model('inception')\n",
    "models['resnet'] = get_trained_model('resnet')\n",
    "models['fc'] = get_trained_model('fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d347d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba56d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6d3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e41254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419a358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd7f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f078fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94b022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
