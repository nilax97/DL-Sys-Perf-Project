{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7b9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Planned datasets - Image (different image sizes/ Different number of classes), \n",
    "##                    Classification (Different feature size / Different number of classes)\n",
    "\n",
    "## Planned models - FC/Dropout, CNN(LeNet)/Resnet/Inception (Maybe include attention)\n",
    "\n",
    "## Predict running time based on Layers/No of params/FLOPs\n",
    "## Calculate total number of computations (based on dataset/model size)\n",
    "## Calculate approx cost on GCP (or any cloud platform)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4b5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc(config):\n",
    "    config['hidden_layers'] = len(config['layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    if config['input_dropout'] is not None:\n",
    "        x = tf.keras.layers.Dropout(config['input_dropout'])(input)\n",
    "    else:\n",
    "        x = input\n",
    "    for i in range(config['hidden_layers']):\n",
    "        dim = config['layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "        if config['dropout'] is not None:\n",
    "            x = tf.keras.layers.Dropout(config['dropout'])(x)\n",
    "            \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_config = dict()\n",
    "fc_config['input_shape'] = 1000\n",
    "fc_config['output_shape'] = 10\n",
    "fc_config['input_dropout'] = 0.2\n",
    "fc_config['dropout'] = 0.5\n",
    "fc_config['hidden_layers'] = 2\n",
    "fc_config['layers'] = [1000,1000]\n",
    "# Output activation = always sigmoid\n",
    "# All hidden layers have same dropout\n",
    "# All hidden layers activated with ReLU\n",
    "# Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "fc_model = create_fc(fc_config)\n",
    "\n",
    "tf.keras.utils.plot_model(fc_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967e71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(x, filters, layers):\n",
    "    for _ in range(layers):\n",
    "        x = tf.keras.layers.Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "def create_vgg(config):\n",
    "    config['num_layers'] = len(config['vgg_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = input\n",
    "    for i in range(config['num_layers']):\n",
    "        block_size = config['vgg_layers'][i]\n",
    "        filter_num = config['filters'][i]\n",
    "        act = 'relu'\n",
    "        x = vgg_block(x,filter_num,block_size)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e2ccc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vgg_config = dict()\n",
    "vgg_config['input_shape'] = (128,128,3)\n",
    "vgg_config['vgg_layers'] = [3,3,3]\n",
    "vgg_config['filters'] = [64,128,256]\n",
    "vgg_config['hidden_layers'] = [100,100]\n",
    "vgg_config['output_shape'] = 20\n",
    "# Output activation = always sigmoid\n",
    "# All convolution layers have 3x3 kernel and same padding\n",
    "# All pooling layers (end of VGG block) reduce image size by half\n",
    "# All hidden layers activated with ReLU\n",
    "# Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "vgg_model = create_vgg(vgg_config)\n",
    "\n",
    "tf.keras.utils.plot_model(vgg_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a831ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = tf.keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    # 3x3 conv\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = tf.keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = tf.keras.layers.Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    pool = tf.keras.layers.BatchNormalization()(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = tf.keras.layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    "\n",
    "def create_inception(config):\n",
    "    config['num_layers'] = len(config['inception_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = tf.keras.layers.Conv2D(64, (7,7), padding='valid', activation='relu', strides=(2,2))(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(192, (3,3), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    for i in range(config['num_layers']):\n",
    "        for j in range(config['inception_layers'][i]):\n",
    "            x = inception_block(x,config['f1'][i][j],config['f2_in'][i][j],config['f2_out'][i][j],\n",
    "                                                    config['f3_in'][i][j],config['f3_out'][i][j],config['f4_out'][i][j])\n",
    "        x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659dad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inception_config = dict()\n",
    "inception_config['input_shape'] = (128,128,3)\n",
    "inception_config['inception_layers'] = [2,5,2]\n",
    "inception_config['f1'] = [[64,128],[192,160,128,112,256],[256,384]]\n",
    "inception_config['f2_in'] = [[96,128],[96,112,128,144,160],[160,192]]\n",
    "inception_config['f2_out'] = [[128,192],[208,224,256,228,320],[320,384]]\n",
    "inception_config['f3_in'] = [[16,32],[16,24,24,32,32],[32,48]]\n",
    "inception_config['f3_out'] = [[32,96],[48,64,64,64,128],[128,128]]\n",
    "inception_config['f4_out'] = [[32,64],[64,64,64,64,128],[128,128]]\n",
    "inception_config['hidden_layers'] = [100,100]\n",
    "inception_config['output_shape'] = 20\n",
    "# Output activation = always sigmoid\n",
    "# All convolution layers have 3x3 kernel and same padding\n",
    "# All pooling layers (end of VGG block) reduce image size by half\n",
    "# All hidden layers activated with ReLU\n",
    "# Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "inception_model = create_inception(inception_config)\n",
    "\n",
    "tf.keras.utils.plot_model(inception_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6ef9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(x, filters, kernel_size, strides=1):\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding = 'same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "def identity_block(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def identity_block_small(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block_small(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def resnet_block(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block(x, filters, strides)\n",
    "        for _ in range(reps-1):\n",
    "                x = identity_block(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def resnet_block_small(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block_small(x, filters, strides)\n",
    "        for _ in range(reps):\n",
    "                x = identity_block_small(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def resnet(config):\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "\n",
    "    x = conv_relu(input, filters=64, kernel_size=7, strides=2)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 3, strides =2)(x)\n",
    "    if config['small']==False:\n",
    "            x = resnet_block(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    else:\n",
    "            x = resnet_block_small(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block_small(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block_small(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block_small(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(config['output_shape'], activation ='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0c147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet_config = dict()\n",
    "resnet_config['input_shape'] = (128,128,3)\n",
    "resnet_config['small'] = False\n",
    "resnet_config['resnet_layers'] = [3,4,6,3]\n",
    "resnet_config['hidden_layers'] = [100,100]\n",
    "resnet_config['output_shape'] = 20\n",
    "resnet_model = resnet(resnet_config)\n",
    "# Output activation = always sigmoid\n",
    "# All resnet blocks have same structure. Can only specify number of repeating blocks (4 list)\n",
    "# Can also specify if small architecture or not (refer paper)\n",
    "# All hidden layers activated with ReLU\n",
    "# Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "tf.keras.utils.plot_model(resnet_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed060086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95ecefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model, batch_size=None,allowed_flops=['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']):\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "\n",
    "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    opts['output'] = 'none'\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
    "                                            run_meta=run_meta, cmd='op', options=opts)\n",
    "    \n",
    "    ret_val = dict()\n",
    "    for fl in allowed_flops:\n",
    "        ret_val[fl] = 0\n",
    "    f = flops.children\n",
    "    while(len(f) > 0):\n",
    "        if f[0].name in allowed_flops:\n",
    "            ret_val[f[0].name] = f[0].total_float_ops\n",
    "        f = f[0].children\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "646afe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    ret_val = dict()\n",
    "    ret_val['trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.trainable_weights])\n",
    "    ret_val['non_trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.non_trainable_weights])\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f462dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    ret_val = dict()\n",
    "    for l in model.layers:\n",
    "        name = l.__class__.__name__\n",
    "        if name in ret_val:\n",
    "            ret_val[name] += 1\n",
    "        else:\n",
    "            ret_val[name] = 1\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "233e4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_flops = ['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']\n",
    "def get_model_params(model,batch_size = 64,x_shape=[]):\n",
    "    flops = get_flops(model)\n",
    "    weights = get_weights(model)\n",
    "    layers = get_layers(model)\n",
    "    \n",
    "    return flops,weights,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95874ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dataset(config):\n",
    "    input_shape = [128] + list(config['input_shape'])\n",
    "    output_shape = [128] + [config['output_shape']]\n",
    "    batch_size = config['batch_size']\n",
    "    x = tf.random.uniform(shape=input_shape)\n",
    "    y = tf.random.uniform(shape=output_shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dad3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.perf_counter()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.perf_counter() - self.epoch_time_start)\n",
    "\n",
    "def run_vgg(config):\n",
    "    model = create_vgg(config)\n",
    "    flops,weights,layers = get_model_params(model)\n",
    "    config['flops_param'] = flops\n",
    "    config['weights_param'] = weights\n",
    "    config['layers_param'] = layers\n",
    "    dataset = create_image_dataset(config)\n",
    "    time_callback = TimeHistory()\n",
    "    steps_per_epoch = config['input_size'] // config['batch_size']\n",
    "    hist = model.fit(dataset,steps_per_epoch=steps_per_epoch, epochs=6, callbacks = [time_callback],verbose=False)\n",
    "    config['train_times'] = time_callback.times[1:]\n",
    "    flops,weights,layers = get_model_params(model)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb1ac427",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_range = dict()\n",
    "vgg_range['input_shape'] = [128,1024,15,0]\n",
    "vgg_range['input_size'] = [10,20,15,1] # Logspace 9\n",
    "vgg_range['vgg_layers'] = [2,10,9,0]\n",
    "vgg_range['vgg_layers_size'] = [1,10,10,0] \n",
    "vgg_range['filters'] = [4,11,8,1] # Logspace 8\n",
    "vgg_range['hidden_layers_size'] = [1,10,10,0]\n",
    "vgg_range['hidden_layers'] = [2,5,7,2] # Logspace 7\n",
    "vgg_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "vgg_range['batch_size'] = [3,10,8,1] #Logspace 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73c9ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [ 128  192  256  320  384  448  512  576  640  704  768  832  896  960\n",
      " 1024]\n",
      "input_size [   1024    1680    2756    4522    7419   12173   19972   32768   53761\n",
      "   88204  144715  237430  389544  639114 1048576]\n",
      "vgg_layers [ 2  3  4  5  6  7  8  9 10]\n",
      "vgg_layers_size [ 1  2  3  4  5  6  7  8  9 10]\n",
      "filters [  16   32   64  128  256  512 1024 2048]\n",
      "hidden_layers_size [ 1  2  3  4  5  6  7  8  9 10]\n",
      "hidden_layers [   100    316   1000   3162  10000  31622 100000]\n",
      "output_shape [   2    4    8   16   32   64  128  256  512 1024]\n",
      "batch_size [   8   16   32   64  128  256  512 1024]\n"
     ]
    }
   ],
   "source": [
    "vgg_params = dict()\n",
    "for key in vgg_range.keys():\n",
    "    val = vgg_range[key]\n",
    "    if val[-1] == 0:\n",
    "        vgg_params[key] = np.linspace(val[0],val[1],num=val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=10).astype('int')\n",
    "\n",
    "for k,v in vgg_params.items():\n",
    "    print(k,v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a0bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_params(params):\n",
    "    config = dict()\n",
    "    for k,v in params.items():\n",
    "        config[k] = v[0]\n",
    "    return config\n",
    "\n",
    "def create_base_vgg_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['vgg_layers'] = [params['vgg_layers']] * params['vgg_layers_size']\n",
    "\n",
    "    filters = []\n",
    "    for i in range(params['vgg_layers_size']):\n",
    "        filters.append(params['filters']*(2**i))\n",
    "    config['filters'] = filters\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"VGG\"\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896602af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running input_shape : 128\n",
      "[0.3916321119759232, 0.39553387300111353, 0.3950996819185093, 0.38934413401875645, 0.3949540989706293]\n",
      "Running input_shape : 192\n",
      "[0.6099827110301703, 0.606804950046353, 0.6062071389751509, 0.6065830120351166, 0.6069266609847546]\n",
      "Running input_shape : 256\n",
      "[1.0368596889311448, 1.0345028389710933, 1.0324806940043345, 1.033559113042429, 1.0405177630018443]\n",
      "Running input_shape : 320\n",
      "[1.5546555001055822, 1.551045150961727, 1.555262957001105, 1.5571821039775386, 1.5457048660609871]\n",
      "Running input_shape : 384\n",
      "[2.1733344619860873, 2.1713483199710026, 2.162825181032531, 2.1684381559025496, 2.176667663967237]\n",
      "Running input_shape : 448\n",
      "[2.9236437019426376, 2.9092045120196417, 2.9215058309491724, 2.92243217502255, 2.9139350689947605]\n",
      "Running input_shape : 512\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key in vgg_params:\n",
    "    base_param = create_base_params(vgg_params)\n",
    "    for value in vgg_params[key]:\n",
    "        print(f'Running {key} : {value}')\n",
    "        filename = f'vgg-{key}-{value}.pickle'\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "        base_param[key] = value\n",
    "        output_config = run_vgg(create_base_vgg_config(base_param))\n",
    "        print(output_config['train_times'])\n",
    "        with open(filename, 'wb') as handle:\n",
    "            pickle.dump(output_config, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3acb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107b147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81949af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf88728f",
   "metadata": {},
   "source": [
    "### Planned parameters : \n",
    "\n",
    "1. Number of cov layers\n",
    "2. Number of dense layers\n",
    "3. Number of total layers\n",
    "\n",
    "4. Conv2D flops\n",
    "5. MaxPool flops\n",
    "6. Bias Addition flops\n",
    "8. Matrix Multiplication flops\n",
    "7. Mean Flops\n",
    "8. Softmax Flops\n",
    "\n",
    "9. Dataset shape (image - max(width,height), fc - input dimension)\n",
    "10. Number of training images\n",
    "11. Output dimensions\n",
    "----------\n",
    "12. Model Type\n",
    "13. Batch Size\n",
    "\n",
    "Include Batch norm (after every layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c858030",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "1. Fully connected\n",
    "\n",
    "fc_config['input_shape'] = 1000 <br>\n",
    "fc_config['output_shape'] = 10 <br>\n",
    "fc_config['input_dropout'] = 0.2 <br>\n",
    "fc_config['dropout'] = 0.5 <br>\n",
    "fc_config['hidden_layers'] = 2 <br>\n",
    "fc_config['layers'] = [1000,1000] <br>\n",
    "\n",
    "2. VGG\n",
    "\n",
    "vgg_config['input_shape'] = (128,128,3) <br>\n",
    "vgg_config['vgg_layers'] = [3,3,3] <br>\n",
    "vgg_config['filters'] = [64,128,256] <br>\n",
    "vgg_config['hidden_layers'] = [100,100] <br>\n",
    "vgg_config['output_shape'] = 20 <br>\n",
    "\n",
    "3. Inception Network\n",
    "\n",
    "inception_config['input_shape'] = (128,128,3) <br>\n",
    "inception_config['inception_layers'] = [2,5,2] <br>\n",
    "inception_config['f1'] = [[64,128],[192,160,128,112,256],[256,384]] <br>\n",
    "inception_config['f2_in'] = [[96,128],[96,112,128,144,160],[160,192]] <br>\n",
    "inception_config['f2_out'] = [[128,192],[208,224,256,228,320],[320,384]] <br>\n",
    "inception_config['f3_in'] = [[16,32],[16,24,24,32,32],[32,48]] <br>\n",
    "inception_config['f3_out'] = [[32,96],[48,64,64,64,128],[128,128]] <br>\n",
    "inception_config['f4_out'] = [[32,64],[64,64,64,64,128],[128,128]] <br>\n",
    "inception_config['hidden_layers'] = [100,100] <br>\n",
    "inception_config['output_shape'] = 20 <br>\n",
    "\n",
    "4. Resnet\n",
    "\n",
    "resnet_config['input_shape'] = (128,128,3) <br>\n",
    "resnet_config['small'] = False <br>\n",
    "resnet_config['resnet_layers'] = [3,4,6,3] <br>\n",
    "resnet_config['hidden_layers'] = [100,100] <br>\n",
    "resnet_config['output_shape'] = 20 <br>\n",
    "resnet_model = resnet(resnet_config) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
