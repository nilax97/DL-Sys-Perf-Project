{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1156be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_fc(config):\n",
    "    config['hidden_layers'] = len(config['layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    if config['input_dropout'] is not None:\n",
    "        x = tf.keras.layers.Dropout(config['input_dropout'])(input)\n",
    "    else:\n",
    "        x = input\n",
    "    for i in range(config['hidden_layers']):\n",
    "        dim = config['layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "        if config['dropout'] is not None:\n",
    "            x = tf.keras.layers.Dropout(config['dropout'])(x)\n",
    "            \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def visualize_fc_config():\n",
    "    fc_config = dict()\n",
    "    fc_config['input_shape'] = 1000\n",
    "    fc_config['output_shape'] = 10\n",
    "    fc_config['input_dropout'] = 0.2\n",
    "    fc_config['dropout'] = 0.5\n",
    "    fc_config['hidden_layers'] = 2\n",
    "    fc_config['layers'] = [1000,1000]\n",
    "    # Output activation = always sigmoid\n",
    "    # All hidden layers have same dropout\n",
    "    # All hidden layers activated with ReLU\n",
    "    # Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "    fc_model = create_fc(fc_config)\n",
    "\n",
    "    return tf.keras.utils.plot_model(fc_model,show_shapes=True,to_file=\"fc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c29598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def vgg_block(x, filters, layers):\n",
    "    for _ in range(layers):\n",
    "        x = tf.keras.layers.Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "def create_vgg(config):\n",
    "    config['num_layers'] = len(config['vgg_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = input\n",
    "    for i in range(config['num_layers']):\n",
    "        block_size = config['vgg_layers'][i]\n",
    "        filter_num = config['filters'][i]\n",
    "        act = 'relu'\n",
    "        x = vgg_block(x,filter_num,block_size)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def visualize_vgg_config():\n",
    "    vgg_config = dict()\n",
    "    vgg_config['input_shape'] = (128,128,3)\n",
    "    vgg_config['vgg_layers'] = [3,3,3]\n",
    "    vgg_config['filters'] = [64,128,256]\n",
    "    vgg_config['hidden_layers'] = [100,100]\n",
    "    vgg_config['output_shape'] = 20\n",
    "    # Output activation = always sigmoid\n",
    "    # All convolution layers have 3x3 kernel and same padding\n",
    "    # All pooling layers (end of VGG block) reduce image size by half\n",
    "    # All hidden layers activated with ReLU\n",
    "    # Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "    vgg_model = create_vgg(vgg_config)\n",
    "\n",
    "    return tf.keras.utils.plot_model(vgg_model,show_shapes=True,to_file=\"vgg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f860a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def inception_block(x, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = tf.keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    # 3x3 conv\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_in, (1,1), padding='same', activation='relu')(x)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = tf.keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = tf.keras.layers.Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    pool = tf.keras.layers.BatchNormalization()(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = tf.keras.layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    "\n",
    "def create_inception(config):\n",
    "    config['num_layers'] = len(config['inception_layers'])\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "    x = tf.keras.layers.Conv2D(64, (7,7), padding='valid', activation='relu', strides=(2,2))(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(192, (3,3), padding='same', activation='relu', strides=(1,1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    for i in range(config['num_layers']):\n",
    "        for j in range(config['inception_layers'][i]):\n",
    "            x = inception_block(x,config['f1'][i][j],config['f2_in'][i][j],config['f2_out'][i][j],\n",
    "                                                    config['f3_in'][i][j],config['f3_out'][i][j],config['f4_out'][i][j])\n",
    "        x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(config['output_shape'],activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def visualize_inception_config():\n",
    "    inception_config = dict()\n",
    "    inception_config['input_shape'] = (128,128,3)\n",
    "    inception_config['inception_layers'] = [2,5,2]\n",
    "    inception_config['f1'] = [[64,128],[192,160,128,112,256],[256,384]]\n",
    "    inception_config['f2_in'] = [[96,128],[96,112,128,144,160],[160,192]]\n",
    "    inception_config['f2_out'] = [[128,192],[208,224,256,228,320],[320,384]]\n",
    "    inception_config['f3_in'] = [[16,32],[16,24,24,32,32],[32,48]]\n",
    "    inception_config['f3_out'] = [[32,96],[48,64,64,64,128],[128,128]]\n",
    "    inception_config['f4_out'] = [[32,64],[64,64,64,64,128],[128,128]]\n",
    "    inception_config['hidden_layers'] = [100,100]\n",
    "    inception_config['output_shape'] = 20\n",
    "    # Output activation = always sigmoid\n",
    "    # All convolution layers have 3x3 kernel and same padding\n",
    "    # All pooling layers (end of VGG block) reduce image size by half\n",
    "    # All hidden layers activated with ReLU\n",
    "    # Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "    inception_model = create_inception(inception_config)\n",
    "\n",
    "    return tf.keras.utils.plot_model(inception_model,show_shapes=True,to_file=\"inception.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98963cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_relu(x, filters, kernel_size, strides=1):\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding = 'same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "def identity_block(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def identity_block_small(tensor, filters):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=1)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([tensor,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=1, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=4*filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def projection_block_small(tensor, filters, strides):\n",
    "        \n",
    "        x = conv_relu(tensor, filters=filters, kernel_size=3, strides=strides)\n",
    "        x = conv_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        \n",
    "        shortcut = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=strides)(tensor)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([shortcut,x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def resnet_block(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block(x, filters, strides)\n",
    "        for _ in range(reps-1):\n",
    "                x = identity_block(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def resnet_block_small(x, filters, reps, strides):\n",
    "        \n",
    "        x = projection_block_small(x, filters, strides)\n",
    "        for _ in range(reps):\n",
    "                x = identity_block_small(x,filters)\n",
    "                \n",
    "        return x\n",
    "\n",
    "def create_resnet(config):\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=config['input_shape'])\n",
    "\n",
    "    x = conv_relu(input, filters=64, kernel_size=7, strides=2)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 3, strides =2)(x)\n",
    "    if config['small']==False:\n",
    "            x = resnet_block(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    else:\n",
    "            x = resnet_block_small(x, filters=64, reps=config['resnet_layers'][0], strides=1)\n",
    "            x = resnet_block_small(x, filters=128, reps=config['resnet_layers'][1], strides=2)\n",
    "            x = resnet_block_small(x, filters=256, reps=config['resnet_layers'][2], strides=2)\n",
    "            x = resnet_block_small(x, filters=512, reps=config['resnet_layers'][3], strides=2)\n",
    "    x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "    config['num_hidden_layers'] = len(config['hidden_layers'])\n",
    "    for i in range(config['num_hidden_layers']):\n",
    "        dim = config['hidden_layers'][i]\n",
    "        act = 'relu'\n",
    "        x = tf.keras.layers.Dense(dim,activation=act)(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(config['output_shape'], activation ='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def visualize_resnet_config():\n",
    "    resnet_config = dict()\n",
    "    resnet_config['input_shape'] = (128,128,3)\n",
    "    resnet_config['small'] = False\n",
    "    resnet_config['resnet_layers'] = [3,4,6,3]\n",
    "    resnet_config['hidden_layers'] = [100,100]\n",
    "    resnet_config['output_shape'] = 20\n",
    "    resnet_model = create_resnet(resnet_config)\n",
    "    # Output activation = always sigmoid\n",
    "    # All resnet blocks have same structure. Can only specify number of repeating blocks (4 list)\n",
    "    # Can also specify if small architecture or not (refer paper)\n",
    "    # All hidden layers activated with ReLU\n",
    "    # Optimizer is always sgd with lr = 0.01 and momentum=0.9\n",
    "\n",
    "    return tf.keras.utils.plot_model(resnet_model,show_shapes=True,to_file=\"resnet.png\")\n",
    "\n",
    "def create_model():\n",
    "    model_creator = dict()\n",
    "    model_creator['vgg'] = create_vgg\n",
    "    model_creator['resnet'] = create_resnet\n",
    "    model_creator['inception'] = create_inception\n",
    "    model_creator['fc'] = create_fc\n",
    "    return model_creator\n",
    "\n",
    "def visualize_model():\n",
    "    model_visualizer = dict()\n",
    "    model_visualizer['vgg'] = visualize_vgg_config\n",
    "    model_visualizer['resnet'] = visualize_resnet_config\n",
    "    model_visualizer['inception'] = visualize_inception_config\n",
    "    model_visualizer['fc'] = visualize_fc_config\n",
    "    return model_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684101e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model, batch_size=None,allowed_flops=['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']):\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "\n",
    "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    opts['output'] = 'none'\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
    "                                            run_meta=run_meta, cmd='op', options=opts)\n",
    "    \n",
    "    ret_val = dict()\n",
    "    for fl in allowed_flops:\n",
    "        ret_val[fl] = 0\n",
    "    f = flops.children\n",
    "    while(len(f) > 0):\n",
    "        if f[0].name in allowed_flops:\n",
    "            ret_val[f[0].name] = f[0].total_float_ops\n",
    "        f = f[0].children\n",
    "    return ret_val\n",
    "\n",
    "def get_weights(model):\n",
    "    ret_val = dict()\n",
    "    ret_val['trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.trainable_weights])\n",
    "    ret_val['non_trainable'] = np.sum([np.product([xi for xi in x.get_shape()]) for x in model.non_trainable_weights])\n",
    "    return ret_val\n",
    "\n",
    "def get_layers(model):\n",
    "    ret_val = dict()\n",
    "    for l in model.layers:\n",
    "        name = l.__class__.__name__\n",
    "        if name in ret_val:\n",
    "            ret_val[name] += 1\n",
    "        else:\n",
    "            ret_val[name] = 1\n",
    "    return ret_val\n",
    "\n",
    "allowed_flops = ['MatMul', 'Mul', 'Rsqrt', 'BiasAdd', 'Sub', 'Softmax', 'Conv2D', 'MaxPool', 'Mean']\n",
    "def get_model_params(model,batch_size = 64,x_shape=[]):\n",
    "    flops = get_flops(model)\n",
    "    weights = get_weights(model)\n",
    "    layers = get_layers(model)\n",
    "    \n",
    "    return flops,weights,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "500f07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def create_image_dataset(config):\n",
    "    input_shape = [128] + list(config['input_shape'])\n",
    "    output_shape = [128] + [config['output_shape']]\n",
    "    batch_size = config['batch_size']\n",
    "    x = tf.random.uniform(shape=input_shape)\n",
    "    y = tf.random.uniform(shape=output_shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def create_fc_dataset(config):\n",
    "    input_shape = [128] + [config['input_shape']]\n",
    "    output_shape = [128] + [config['output_shape']]\n",
    "    batch_size = config['batch_size']\n",
    "    x = tf.random.uniform(shape=input_shape)\n",
    "    y = tf.random.uniform(shape=output_shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def run_fc(config):\n",
    "    model = create_fc(config)\n",
    "    flops,weights,layers = get_model_params(model)\n",
    "    config['flops_param'] = flops\n",
    "    config['weights_param'] = weights\n",
    "    config['layers_param'] = layers\n",
    "    dataset = create_fc_dataset(config)\n",
    "    time_callback = TimeHistory()\n",
    "    steps_per_epoch = config['input_size'] // config['batch_size']\n",
    "    hist = model.fit(dataset,steps_per_epoch=steps_per_epoch, epochs=6, callbacks = [time_callback],verbose=False)\n",
    "    config['train_times'] = time_callback.times[1:]\n",
    "    return config\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.perf_counter()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.perf_counter() - self.epoch_time_start)\n",
    "        \n",
    "def run_model(config,model_type):\n",
    "    model = create_model()[model_type](config)\n",
    "    flops,weights,layers = get_model_params(model)\n",
    "    config['flops_param'] = flops\n",
    "    config['weights_param'] = weights\n",
    "    config['layers_param'] = layers\n",
    "    dataset = create_image_dataset(config)\n",
    "    time_callback = TimeHistory()\n",
    "    steps_per_epoch = config['input_size'] // config['batch_size']\n",
    "    hist = model.fit(dataset,steps_per_epoch=steps_per_epoch, epochs=6, callbacks = [time_callback],verbose=False)\n",
    "    config['train_times'] = time_callback.times[1:]\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69a05d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_range = dict()\n",
    "vgg_range['input_shape'] = [128,1024,15,0]\n",
    "vgg_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "vgg_range['vgg_layers'] = [2,10,9,0]\n",
    "vgg_range['vgg_layers_size'] = [1,7,7,0] \n",
    "vgg_range['filters'] = [4,10,7,1] # Logspace 8\n",
    "vgg_range['hidden_layers_size'] = [1,10,10,0]\n",
    "vgg_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "vgg_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "vgg_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "inception_range = dict()\n",
    "inception_range['input_shape'] = [128,1024,15,0]\n",
    "inception_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "inception_range['inception_layers'] = [1,5,5,0]\n",
    "inception_range['f1'] = [64,320,5,0]\n",
    "inception_range['f2_in'] = [128,384,5,0]\n",
    "inception_range['f2_out'] = [192,448,5,0]\n",
    "inception_range['f3_in'] = [32,160,5,0]\n",
    "inception_range['f3_out'] = [32,160,5,0]\n",
    "inception_range['f4_out'] = [32,160,5,0]\n",
    "inception_range['hidden_layers_size'] = [1,10,10,0]\n",
    "inception_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "inception_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "inception_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "resnet_range = dict()\n",
    "resnet_range['input_shape'] = [128,1024,15,0]\n",
    "resnet_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "resnet_range['resnet_layers'] = [3,7,5,0]\n",
    "resnet_range['hidden_layers_size'] = [1,10,10,0]\n",
    "resnet_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "resnet_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "resnet_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "fc_range = dict()\n",
    "fc_range['input_shape'] = [128,1024,15,0]\n",
    "fc_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "fc_range['hidden_layers'] = [1,10,10,0]\n",
    "fc_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "fc_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "def get_ranges():\n",
    "    ranges = dict()\n",
    "    ranges['vgg'] = vgg_range\n",
    "    ranges['resnet'] = resnet_range\n",
    "    ranges['inception'] = inception_range\n",
    "    ranges['fc'] = fc_range\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7ead0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(model_range):\n",
    "    params = dict()\n",
    "    for key in model_range.keys():\n",
    "        val = model_range[key]\n",
    "        if val[-1] == 0:\n",
    "            params[key] = np.linspace(val[0],val[1],num=val[2]).astype('int')\n",
    "        elif val[-1] == 1:\n",
    "            params[key] = np.logspace(val[0],val[1],num=val[2],base=2).astype('int')\n",
    "        elif val[-1] == 2:\n",
    "            params[key] = np.logspace(val[0],val[1],num=val[2],base=10).astype('int')\n",
    "    return params\n",
    "\n",
    "def create_base_params(params):\n",
    "    config = dict()\n",
    "    for k,v in params.items():\n",
    "        config[k] = v[0]\n",
    "    return config\n",
    "\n",
    "\n",
    "def create_base_vgg_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['vgg_layers'] = [params['vgg_layers']] * params['vgg_layers_size']\n",
    "\n",
    "    filters = []\n",
    "    for i in range(params['vgg_layers_size']):\n",
    "        filters.append(params['filters']*(2**i))\n",
    "    config['filters'] = filters\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"VGG\"\n",
    "    return config\n",
    "\n",
    "def create_base_inception_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['inception_layers'] = [params['inception_layers']] * 3\n",
    "\n",
    "    config['f1'] = []\n",
    "    config['f2_in'] = []\n",
    "    config['f2_out'] = []\n",
    "    config['f3_in'] = []\n",
    "    config['f3_out'] = []\n",
    "    config['f4_out'] = []\n",
    "\n",
    "    for val in config['inception_layers']:\n",
    "        config['f1'].append([params['f1']]*val)\n",
    "        config['f2_in'].append([params['f2_in']]*val)\n",
    "        config['f2_out'].append([params['f2_out']]*val)\n",
    "        config['f3_in'].append([params['f3_in']]*val)\n",
    "        config['f3_out'].append([params['f3_out']]*val)\n",
    "        config['f4_out'].append([params['f4_out']]*val)\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"Inception\"\n",
    "    return config\n",
    "\n",
    "def create_base_resnet_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = (params['input_shape'],params['input_shape'],3)\n",
    "    config['small'] = False\n",
    "    config['resnet_layers'] = [params['resnet_layers']] * 4\n",
    "\n",
    "    config['hidden_layers'] = [params['hidden_layers']] * params['hidden_layers_size']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"ResNet\"\n",
    "    return config\n",
    "\n",
    "def create_base_fc_config(params):\n",
    "    config = dict()\n",
    "    config['input_shape'] = params['input_shape']\n",
    "    config['input_dropout'] = 0.2\n",
    "    config['dropout'] = 0.5\n",
    "\n",
    "    config['layers'] = [1000] * params['hidden_layers']\n",
    "    config['output_shape'] = params['output_shape']\n",
    "\n",
    "    config['input_size'] = params['input_size']\n",
    "    config['batch_size'] = params['batch_size']\n",
    "    \n",
    "    config['model'] = \"FC\"\n",
    "    return config\n",
    "\n",
    "def create_config():\n",
    "    config_creator = dict()\n",
    "    config_creator['vgg'] = create_base_vgg_config\n",
    "    config_creator['resnet'] = create_base_resnet_config\n",
    "    config_creator['inception'] = create_base_inception_config\n",
    "    config_creator['fc'] = create_base_fc_config\n",
    "    return config_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eaf012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def run_experiment(model_type):\n",
    "    params = get_params(get_ranges()[model_type])\n",
    "    for key in params:\n",
    "        base_param = create_base_params(params)\n",
    "        for value in params[key]:\n",
    "            print(f'[{model_type}] Running {key} : {value}')\n",
    "            filename = f'{model_type}/{model_type}-{key}-{value}.pickle'\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, 'rb') as handle:\n",
    "                    output_config = pickle.load(handle)\n",
    "                    print(output_config['train_times'])\n",
    "                continue\n",
    "            base_param[key] = value\n",
    "            output_config = run_model(create_config()[model_type](base_param),model_type)\n",
    "            print(output_config['train_times'])\n",
    "            with open(filename, 'wb') as handle:\n",
    "                pickle.dump(output_config, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab969c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95131af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
