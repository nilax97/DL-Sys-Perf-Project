{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xIjIhbxuf_B3"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_range = dict()\n",
    "vgg_range['input_shape'] = [128,1024,15,0]\n",
    "vgg_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "vgg_range['vgg_layers'] = [2,10,9,0]\n",
    "vgg_range['vgg_layers_size'] = [1,7,7,0] \n",
    "vgg_range['filters'] = [4,10,7,1] # Logspace 8\n",
    "vgg_range['hidden_layers_size'] = [1,10,10,0]\n",
    "vgg_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "vgg_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "vgg_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "vgg_params = dict()\n",
    "for key in vgg_range.keys():\n",
    "    val = vgg_range[key]\n",
    "    if val[-1] == 0:\n",
    "        vgg_params[key] = np.linspace(val[0],val[1],num=val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        vgg_params[key] = np.logspace(val[0],val[1],num=val[2],base=10).astype('int')\n",
    "\n",
    "inception_range = dict()\n",
    "inception_range['input_shape'] = [128,1024,15,0]\n",
    "inception_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "inception_range['inception_layers'] = [1,5,5,0]\n",
    "inception_range['f1'] = [64,320,5,0]\n",
    "inception_range['f2_in'] = [128,384,5,0]\n",
    "inception_range['f2_out'] = [192,448,5,0]\n",
    "inception_range['f3_in'] = [32,160,5,0]\n",
    "inception_range['f3_out'] = [32,160,5,0]\n",
    "inception_range['f4_out'] = [32,160,5,0]\n",
    "inception_range['hidden_layers_size'] = [1,10,10,0]\n",
    "inception_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "inception_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "inception_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "inception_params = dict()\n",
    "for key in inception_range.keys():\n",
    "    val = inception_range[key]\n",
    "    if val[-1] == 0:\n",
    "        inception_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        inception_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        inception_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "        \n",
    "resnet_range = dict()\n",
    "resnet_range['input_shape'] = [128,1024,15,0]\n",
    "resnet_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "resnet_range['resnet_layers'] = [3,7,5,0]\n",
    "resnet_range['hidden_layers_size'] = [1,10,10,0]\n",
    "resnet_range['hidden_layers'] = [2,3.5,4,2] # Logspace 7\n",
    "resnet_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "resnet_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "resnet_params = dict()\n",
    "for key in resnet_range.keys():\n",
    "    val = resnet_range[key]\n",
    "    if val[-1] == 0:\n",
    "        resnet_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        resnet_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        resnet_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "\n",
    "\n",
    "fc_range = dict()\n",
    "fc_range['input_shape'] = [128,1024,15,0]\n",
    "fc_range['input_size'] = [10,19,10,1] # Logspace 9\n",
    "fc_range['hidden_layers'] = [1,10,10,0]\n",
    "fc_range['output_shape'] = [1,10,10,1] # Logspace 10\n",
    "fc_range['batch_size'] = [3,10,8,1] #Logspace 8\n",
    "\n",
    "fc_params = dict()\n",
    "for key in fc_range.keys():\n",
    "    val = fc_range[key]\n",
    "    if val[-1] == 0:\n",
    "        fc_params[key] = np.linspace(val[0],val[1],num = val[2]).astype('int')\n",
    "    elif val[-1] == 1:\n",
    "        fc_params[key] = np.logspace(val[0],val[1],num = val[2],base = 2).astype('int')\n",
    "    elif val[-1] == 2:\n",
    "        fc_params[key] = np.logspace(val[0],val[1],num = val[2],base = 10).astype('int')\n",
    "        \n",
    "params = dict()\n",
    "params['vgg'] = vgg_params\n",
    "params['resnet'] = resnet_params\n",
    "params['inception'] = inception_params\n",
    "params['fc'] = fc_params\n",
    "\n",
    "def get_time_train_data(folder_name):\n",
    "    x = []\n",
    "    y = []\n",
    "    model_params = params[folder_name]\n",
    "    for key in model_params:\n",
    "        for value in model_params[key]:\n",
    "            filename = f'{folder_name}/{folder_name}-{key}-{value}.pickle'\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, 'rb') as handle:\n",
    "                    output_config = pickle.load(handle)\n",
    "                    x.append(list(output_config['flops_param'].values()) + \n",
    "                             list(output_config['layers_param'].values()) + \n",
    "                             list(output_config['weights_param'].values()))\n",
    "                    x[-1].append(output_config['input_size'])\n",
    "                    x[-1].append(output_config['batch_size'])\n",
    "                    y.append(list(output_config['train_times']))\n",
    "    x = np.asarray(x).astype('float64')\n",
    "    y = np.asarray(y).astype('float64')\n",
    "    y = np.mean(y,axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_single_time_train_data(output_config):\n",
    "    x = []\n",
    "    y = []\n",
    "    x.append(list(output_config['flops_param'].values()) + \n",
    "             list(output_config['layers_param'].values()) + \n",
    "             list(output_config['weights_param'].values()))\n",
    "    x[-1].append(output_config['input_size'])\n",
    "    x[-1].append(output_config['batch_size'])\n",
    "    y.append(list(output_config['train_times']))\n",
    "    x = np.asarray(x).astype('float64')\n",
    "    y = np.asarray(y).astype('float64')\n",
    "    y = np.mean(y,axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_trained_model(folder_name):\n",
    "    x,y = get_time_train_data(folder_name)\n",
    "    min_error = float('inf')\n",
    "    min_model = None\n",
    "    for i in range(100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "        rf = RandomForestRegressor(n_estimators=20)\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred_train = rf.predict(x_train)\n",
    "        y_pred_test = rf.predict(x_test)\n",
    "        train_error = mean_absolute_percentage_error(y_train,y_pred_train)\n",
    "        test_error = mean_absolute_percentage_error(y_test,y_pred_test)\n",
    "        if test_error < min_error:\n",
    "            min_loss = test_error\n",
    "            min_model = rf\n",
    "        if (test_error - train_error) < 0.05 and max(test_error,train_error) < 0.1:\n",
    "            break\n",
    "    y_pred_train = min_model.predict(x_train)\n",
    "    y_pred_test = min_model.predict(x_test)\n",
    "    print(f'{folder_name} - train MSE : {mean_absolute_percentage_error(y_train,y_pred_train)}')\n",
    "    print(f'{folder_name} - test MSE : {mean_absolute_percentage_error(y_test,y_pred_test)}')\n",
    "    \n",
    "    return min_model\n",
    "\n",
    "models = dict()\n",
    "models['vgg'] = get_trained_model('vgg')\n",
    "models['inception'] = get_trained_model('inception')\n",
    "models['resnet'] = get_trained_model('resnet')\n",
    "models['fc'] = get_trained_model('fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open('vgg/vgg-filters-128.pickle', \"rb\")\n",
    "data = pickle.load(file_to_read)\n",
    "x,y = get_single_time_train_data(data)\n",
    "y_pred = models['vgg'].predict(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A78JbzC6WtWS"
   },
   "outputs": [],
   "source": [
    "def get_model_stored_train_times(dir_path):\n",
    "    # Necessary Imports\n",
    "    data_dict = defaultdict(list)\n",
    "\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        file_name_elems = file_name.split('-')\n",
    "        varying_attr_name = file_name_elems[1]\n",
    "        varying_attr_val = int(file_name_elems[2][:file_name_elems[2].find('.')])\n",
    "\n",
    "        # Forming a list of tuples for each of the varying attributes...\n",
    "        if varying_attr_name not in data_dict.keys():\n",
    "            data_dict[varying_attr_name] = []\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            file_to_read = open(file_path, \"rb\")\n",
    "            data = pickle.load(file_to_read)\n",
    "            x,y = get_single_time_train_data(data)\n",
    "            y_pred = models[dir_path].predict(x)[0]\n",
    "            data_dict[varying_attr_name].append([varying_attr_val, np.mean(data['train_times']), y_pred])\n",
    "\n",
    "    # Sorting the list of tuples to get cleaner analysis\n",
    "    for varying_attr_name, varying_attr_vals in data_dict.items():\n",
    "        data_dict[varying_attr_name] = sorted(varying_attr_vals, key = lambda x : x[0])\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvRes_qiNdy9",
    "outputId": "e11320ec-2a62-4100-c618-fb9b55b9cebd"
   },
   "outputs": [],
   "source": [
    "# VGG\n",
    "dir_path = os.path.join(\"vgg\")\n",
    "vgg_data_dict = get_model_stored_train_times(dir_path)\n",
    "print(vgg_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP5SvRd2Xxmh",
    "outputId": "89b5fd91-c540-49de-abdf-69eba0e5f300"
   },
   "outputs": [],
   "source": [
    "# ResNet\n",
    "dir_path = os.path.join(\"resnet\")\n",
    "resnet_data_dict = get_model_stored_train_times(dir_path)\n",
    "print(resnet_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezaRUR8jXxZ_",
    "outputId": "7df93ef7-e867-4e39-c983-a07785ba01a3"
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "dir_path = os.path.join(\"inception\")\n",
    "inception_data_dict = get_model_stored_train_times(dir_path)\n",
    "print(inception_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8yc-xstXxPY",
    "outputId": "5e15df0e-9340-4468-9db1-ec9f10a4df06"
   },
   "outputs": [],
   "source": [
    "# fc\n",
    "dir_path = os.path.join(\"fc\")\n",
    "fc_data_dict = get_model_stored_train_times(dir_path)\n",
    "print(fc_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtUSURhlMVBZ"
   },
   "outputs": [],
   "source": [
    "# Visualize all the data for the training times\n",
    "def plot_varying_attrs_vs_train_times(model_name, dict_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "#     plt.rcParams[\"figure.figsize\"] = (15,40)\n",
    "    num_plots = len(dict_data)\n",
    "    fig, axs = plt.subplots(num_plots,figsize=(15,num_plots*5))\n",
    "    print(f'Training Times (y-axis) for Models (with varying attributes): {model_name.upper()}')\n",
    "\n",
    "    plt_counter = 0\n",
    "    for varying_attr_name, varying_attr_vals in dict_data.items():\n",
    "        x_vals = [attr[0] for attr in varying_attr_vals]\n",
    "        y_vals = [attr[1] for attr in varying_attr_vals]\n",
    "        y_pred_vals = [attr[2] for attr in varying_attr_vals]\n",
    "        axs[plt_counter].set_title(varying_attr_name)\n",
    "        axs[plt_counter].plot(x_vals,y_vals,c='blue',label='Actual')\n",
    "        axs[plt_counter].plot(x_vals,y_pred_vals,c='orange',label='Predicted')\n",
    "        axs[plt_counter].legend()\n",
    "#         sns.barplot(x_vals, y_vals, ax = axs[plt_counter])\n",
    "        plt_counter += 1\n",
    "    \n",
    "    # Saving the image\n",
    "    plt.savefig(os.path.join(\"Visualizations\", f'{model_name}_data_vs.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JYO9MMHydHsT",
    "outputId": "dc44bf4c-1960-4cb5-e9a1-3577dd423876",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VGG Visualizations\n",
    "plot_varying_attrs_vs_train_times('VGG', vgg_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cs__7rOrdHoG",
    "outputId": "dc42c9a4-3538-47db-dd7d-d889800ef2c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ResNet Visualizations\n",
    "plot_varying_attrs_vs_train_times('ResNet', resnet_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NKDbClBOdHbZ",
    "outputId": "100eadca-8134-45d5-a15c-205b537ed8cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inception Visualizations\n",
    "plot_varying_attrs_vs_train_times('Inception', inception_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cw1Efng5dHXz",
    "outputId": "799552a9-293f-4270-f7c5-245587e9113a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fc Visualizations\n",
    "plot_varying_attrs_vs_train_times('Fully Connected', fc_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUa9ZNl5tYJz"
   },
   "outputs": [],
   "source": [
    "def get_model_train_times_per_aux_vars(dir_path):\n",
    "    # Necessary Imports\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import defaultdict\n",
    "    import pickle\n",
    "\n",
    "    data_dict = defaultdict(dict)\n",
    "\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        if file_name.find(\"input_shape\") == -1 and file_name.find(\"layers\") == -1:\n",
    "            continue\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        file_name_elems = file_name.split('-')\n",
    "        varying_attr_name = file_name_elems[1]\n",
    "\n",
    "        # Forming a dict of list of tuples for each of the varying attributes...\n",
    "        if varying_attr_name not in data_dict.keys():\n",
    "            data_dict[varying_attr_name] = dict()\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            file_to_read = open(file_path, \"rb\")\n",
    "            data = pickle.load(file_to_read)\n",
    "            \n",
    "            x,y = get_single_time_train_data(data)\n",
    "            y_pred = models[dir_path].predict(x)[0]\n",
    "\n",
    "            total_flops = sum(list(data['flops_param'].values()))\n",
    "            if 'flops_param' not in data_dict[varying_attr_name].keys():\n",
    "                data_dict[varying_attr_name]['flops_param'] = []\n",
    "            data_dict[varying_attr_name]['flops_param'].append((total_flops, np.mean(data['train_times']),y_pred))\n",
    "\n",
    "            trainable_params = data['weights_param']['trainable']\n",
    "            if 'trainable' not in data_dict[varying_attr_name].keys():\n",
    "                data_dict[varying_attr_name]['trainable'] = []\n",
    "            data_dict[varying_attr_name]['trainable'].append((trainable_params, np.mean(data['train_times']),y_pred))\n",
    "\n",
    "            total_depth = sum(list(data['layers_param'].values()))\n",
    "            if 'layers_param' not in data_dict[varying_attr_name].keys():\n",
    "                data_dict[varying_attr_name]['layers_param'] = []\n",
    "            data_dict[varying_attr_name]['layers_param'].append((total_depth, np.mean(data['train_times']),y_pred))\n",
    "\n",
    "    # Sorting the list of tuples to get cleaner analysis\n",
    "    for varying_attr_name, varying_attr_vals in data_dict.items():\n",
    "        for varying_attr_val_name, varying_data in varying_attr_vals.items():\n",
    "            data_dict[varying_attr_name][varying_attr_val_name] = sorted(varying_data, key = lambda x : x[0])\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lysEgKBQtYG6",
    "outputId": "ab4c38aa-2dab-4332-f695-d5fff03681c3"
   },
   "outputs": [],
   "source": [
    "# VGG\n",
    "dir_path = os.path.join(\"vgg\")\n",
    "vgg_data_dict_2 = get_model_train_times_per_aux_vars(dir_path)\n",
    "print(vgg_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJIlEGL5tYED",
    "outputId": "3c887244-c5cb-4bbe-ef20-38d6a03bf35c"
   },
   "outputs": [],
   "source": [
    "# ResNet\n",
    "dir_path = os.path.join(\"resnet\")\n",
    "resnet_data_dict_2 = get_model_train_times_per_aux_vars(dir_path)\n",
    "print(resnet_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ei_sJfvtYBF",
    "outputId": "ccc30fcc-3d30-48bb-fa26-499f0841c0ee"
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "dir_path = os.path.join(\"inception\")\n",
    "inception_data_dict_2 = get_model_train_times_per_aux_vars(dir_path)\n",
    "print(inception_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH9-3ukitX4O",
    "outputId": "5a07325e-aed5-4cc9-ff8d-25da80f3899a"
   },
   "outputs": [],
   "source": [
    "# fc\n",
    "dir_path = os.path.join(\"fc\")\n",
    "fc_data_dict_2 = get_model_train_times_per_aux_vars(dir_path)\n",
    "print(fc_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Tya3qrTAG5C"
   },
   "outputs": [],
   "source": [
    "aux_vars = ['flops_param', 'trainable', 'layers_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfRDgvjoAG2e"
   },
   "outputs": [],
   "source": [
    "# Visualize all the data for the training times\n",
    "def plot_varying_aux_attrs_vs_train_times(model_name, dict_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "#     plt.rcParams[\"figure.figsize\"] = (15,80)\n",
    "    num_plots = len(dict_data)*len(aux_vars)\n",
    "    fig, axs = plt.subplots(num_plots,figsize=(15,num_plots*5))\n",
    "    print(f'Training Times (y-axis) for Models (with varying attributes): {model_name.upper()}')\n",
    "\n",
    "\n",
    "    plt_counter = 0\n",
    "    for varying_attr_name, varying_attr_vals in dict_data.items():\n",
    "        for varying_attr_val_name, varying_attr_data in varying_attr_vals.items():\n",
    "            x_vals = [x[0] for x in varying_attr_data]\n",
    "            y_vals = [x[1] for x in varying_attr_data]\n",
    "            y_pred_vals = [x[2] for x in varying_attr_data]\n",
    "            axs[plt_counter].set_title(f\"{varying_attr_val_name} w.r.t {varying_attr_name}\")\n",
    "            axs[plt_counter].plot(x_vals,y_vals,c='blue',label='Actual')\n",
    "            axs[plt_counter].plot(x_vals,y_pred_vals,c='orange',label='Predicted')\n",
    "            axs[plt_counter].legend()\n",
    "#             sns.barplot(x_vals, y_vals, ax = axs[plt_counter])\n",
    "            plt_counter += 1\n",
    "    \n",
    "    # Saving the image\n",
    "    plt.savefig(os.path.join(\"Visualizations\", f'{model_name}_aux_vars_data_vs.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WdRSipYVAGzi",
    "outputId": "255707fc-a3e8-46b8-e9b6-0f125f996466",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VGG Aux Variable Visualizations\n",
    "plot_varying_aux_attrs_vs_train_times('VGG', vgg_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bZ5ktExzAGwq",
    "outputId": "756c698d-9971-4596-fd93-f63dfb564fe4"
   },
   "outputs": [],
   "source": [
    "# ResNet Aux Variable Visualizations\n",
    "plot_varying_aux_attrs_vs_train_times('ResNet', resnet_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f2mFQCWpAGti",
    "outputId": "a20586f3-2543-40e5-b96e-188e12015873"
   },
   "outputs": [],
   "source": [
    "# Inception Aux Variable Visualizations\n",
    "plot_varying_aux_attrs_vs_train_times('Inception', inception_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fCNN5FL0AGpW",
    "outputId": "76fa09fb-0e37-4007-c3b9-c940c0c4cc04"
   },
   "outputs": [],
   "source": [
    "# fc Aux Variable Visualizations\n",
    "plot_varying_aux_attrs_vs_train_times('Fully Connected', fc_data_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "HH_DmoA6E4H6",
    "outputId": "4db317bb-b1b4-4637-d421-823ed8005841"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Analysis_v2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
